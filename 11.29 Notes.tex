\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\title{11.29 Notes}
\author{Math 403/503}
\date{November 2022}

\begin{document}

\maketitle

\section{Trace and Determinant}
Recall from our discussion of eigenvalues that any operator $T$ in $L(C^n)$ has n-many eigenvalues IF we count multiplicity, that is, how many times each $\lambda$ appears in the diagonalization (or Jordan form). Officially the \underline{multiplicity} of an eigenvalues $\lambda$ of $T$ is equal to dim G($\lambda, T$). From now on, if we say "the eigenvalues of $T \epsilon L(C^n)$ are $\lambda_1, ..., \lambda_n$" we mean that each $\lambda$ appears multiple times in the list according to its multiplicity. \\\\
Example: If $T$ has matrix $\begin{bmatrix} 
1&3&4\\0&1&5\\0&0&2
\end{bmatrix}$ we would say the eigenvalues of $T$ are $1, 1, 2$. \\\\
\textbf{Definition}: If $T \epsilon L(C^n)$ then the \underline{trace} of $T$ denoted trace(T) or tr(T) is equal to tr(T) $= \lambda_1 + ... + \lambda_n.$ Where the eigenvalues of $T$ are $\lambda_1, ..., \lambda_n$. \\\\
Example: If $T$ has matrix $\begin{bmatrix} 
1&3&4\\0&1&5\\0&0&2
\end{bmatrix}$ then tr(T) = 4 (not 3). \\\\
Example: If $T$ has matrix $\begin{bmatrix}
3&-1&2\\3&2&-3\\1&2&0
\end{bmatrix}$ then the eigenvalues are $\lambda_1 = 1, \lambda_2 = 2 + 3i, \lambda_3 = 2 - 3i$. Thus the tr(T)$ = 1+2+3i + 2 - 3i = 5$. Observe the imaginary parts cancelled (because the matrix has real entries) Observe if $T$ has a triangular matrix, the eigenvalues appear down the diagonal with their multiplicities so tr(T) = the sum of the diagonal entries. Observe in our non-triangular example, the trace was ALSO the sum of the diagonal entries...\\\\
For now, let's define two separate concepts: \\ 
trace(T) = sum of eigenvalues \\
dsum(A) = sum of diagonal entries. \\
Our goal is to show that the two concepts are the same, that is, if $A$ is the matrix of $T$ in some basis then trace(T) = dsum(A). \\\\
\textbf{Lemma}: dsum(AB) = dsum(BA). \\\\
\textbf{Proof}: Write $A$ as an n by n matrix with $a_{11}$ as the top left entry and $a_{nn}$ as the bottom right entry, $B$ would be written similarly.  then the jj entry of AB is $\sum_{k=1}^{n} a_{jk} b_{kj}$. And the kk entry of BA is $\sum_{j=1}^{n} b_{kj} a_{jk}$\\\\
dsum(AB) = $\sum_{j}$ jj entry of AB \\ = $\sum_{j} \sum_{k} a_{jk} b{kj}$ \\ = $\sum_{k} \sum_{j} a_{jk} b{kj}$ \\ = $\sum_{k} \sum_{j} b_{kj} a_{jk}$\\ = $\sum_{k}$ kk entry of BA. \\\\ 
Next we explore what happens to dsum(A) when we change basis: $B^{-1}AB$. \\\\
\textbf{Lemma}: dsum($B^{-1}AB$) = dsum(A). \\\\
\textbf{Proof}: dsum($B^{-1}AB$) = dsum($BB^{-1}A$ = dsum(A). \\\\
\textbf{Theorem}: If $T$ has matrix $A$ in some basis, then trace(T) = dsum(A). \\\\
\textbf{Proof}: By the above, we may assume without loss of generality, that we are working in a basis where $A$ is upper triangular. In this case we already know the diagonal of $A$ must be the eigenvalues $\lambda_1, ..., \lambda_n$ thus trace(T) = dsum(A). \\\\
From now on, we say trace for both concepts. trace(T) = trace(A) for any matrix $A$ representing $T$. 
\section{Properties of the Trace}
\begin{itemize}
    \item trace(ST) = trace(TS) 
    \item trace($\alpha T$) = $\alpha$ trace(T)
    \item trace(S + T) = trace(S) + trace(T) 
\end{itemize}
The proof of all three is because they are true for the diagonal sum. \\\\
One applicatin of the trace is to "commutators". If operators $S,T$ commute, $ST = TS$. If they don't commute, $ST \neq TS$ which means $ST - TS \neq 0$. Thus $ST - TS$ somehow measures how much $S$ and $T$ fail to commute. It gets a notation: the "commutator" of $S$ and $T$ is $[S,T] = ST - TS$. \\\\
\textbf{Theorem}: $[S,T]$ is never equal to the identity. \\\\
\textbf{Proof}: Compare the trace of both sides.
\begin{itemize} 
\item trace($[S,T]$) = trace($ST - TS$) = trace ($ST$) - trace ($TS$) = 0.
\item trace(I) = 1 + ... + 1 = n
\end{itemize}
Thus the two items cannot be equal. \\\\
\section{Next Time}
The \underline{determinant} of $T$ is $\lambda_1, ..., \lambda_n$ the product. Like the trace, the determinant can be calculated from matrices. Like the trace, the determinant satisfies nice properties (though different ones). The determinant has several very central applications including in calculus. 

\end{document}
